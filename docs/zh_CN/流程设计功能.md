## 4.5 流程设计

ArkLifter支持多种不同种类的任务调度，不同的类型的任务调度对应不同的设计方式。

脚本类任务：shell脚本，hive sql，sparkSQL，prestoSQL都需要先在**脚本设计**模块编写脚本并保存，这些脚本都会持久化到数据库中。然后在流程设计界面拖拽对应的任务节点，并在下拉框中选择对应的脚本，配置参数即可。

程序类任务：mr程序，spark程序都需要先将程序打成zip包上传到HDFS上，然后在流程设计界面拖拽对应的任务节点，并选择对应的HDFS上的程序包路径，配置参数即可。

以上都是**业务节点**的设计步骤，针对**逻辑节点**只需要直接在流程设计界面拖拽对应的任务节点，然后配置参数即可。

### 4.5.1 脚本设计

1. shell脚本任务

    shell脚本可以支持参数，工作流调度时会将用户设置的参数按顺序传入，shell脚本里只要获取\$1 \$2...就行了。脚本内容写入输入文本域中保存即可。
    
2. hiveSQL

    hiveSQL脚本同样是将脚本写入到文本域中，多个sql以‘；’分隔开。

5. sparkSQL

    同上

6. prestoSQL
    
    同上

### 4.5.2 任务节点设计

为了方便任务类型的扩展，我们将流程的任务类型设计为模块化可插拔的方式。每种任务类型都需要维护它自己的一个配置文件metainfo.xml，这个配置文件描述了这个任务类型在界面上可见的form元素，该任务的具体执行器runner的class。比如shell类型的任务节点的元素有**任务名称**，**脚本路径**，**脚本类型**，**是否可重试**，**最大重试次数**，**顺序输入参数列表**等。当escheduler-server启动时会在classpath下找tasks/${taskType}/metainfo.xml，然后读取该文件中的内容并持久化到数据库。在流程设计界面每个任务类型看能看到的配置信息都是从数据库中读取的，在任务被调度执行时，具体的执行逻辑是从库中找到该任务类型对应的执行器class，通过JDK反射的方式进行调用。基于以上方式实现了一个可插拔的工作流任务列表。如果用户想创建自己的工作流任务类型，只需要按格式生成自己的metainfo.xml文件，继承执行器的基类，然后实现一些方法即可打包后放到escheduler软件的Lib目录下重启服务即可。

### 4.5.3 流程图设计

每个工作流都必须从一个start任务节点开始，然后根据自己的需要拖拽不同的任务类型的节点并连线即可完成流程图的设计。流程图必须是一个DAG图（有向无环图），不能出现循环和首尾相连的情况。







